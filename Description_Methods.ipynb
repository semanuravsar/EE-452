{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e8b9c-8894-46f9-9364-93b5dfa38232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from seiz_eeg.dataset import EEGDataset\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader  \n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.nn import GINEConv\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GINConv\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool, global_max_pool\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from scipy.signal import stft\n",
    "from scipy.signal import welch\n",
    "from sklearn.metrics import mutual_info_score\n",
    "from torch_geometric.utils import dropout_edge\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from torch_geometric.data import Data\n",
    "from scipy.signal import resample, correlate\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import Dataset, Subset, random_split\n",
    "from torch_geometric.data import Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e991876d-de3d-476e-a50c-371459047f23",
   "metadata": {},
   "source": [
    "### Preprocessing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7d5c1-6fe5-4e66-8462-91e5790d3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_filter = signal.butter(4, (0.5, 30), btype=\"bandpass\", output=\"sos\", fs=250)\n",
    "\n",
    "\n",
    "def time_filtering(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Filter signal in the time domain\"\"\"\n",
    "    return signal.sosfiltfilt(bp_filter, x, axis=0).copy()\n",
    "\n",
    "\n",
    "def fft_filtering(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute FFT and only keep\"\"\"\n",
    "    x = np.abs(np.fft.fft(x, axis=0))\n",
    "    x = np.log(np.where(x > 1e-8, x, 1e-8))\n",
    "\n",
    "    win_len = x.shape[0]\n",
    "    # Only frequencies b/w 0.5 and 30Hz\n",
    "    return x[int(0.5 * win_len // 250) : 30 * win_len // 250]\n",
    "\n",
    "\n",
    "def stft_transform(x: np.ndarray, fs=250, nperseg=128, noverlap=64) -> np.ndarray:\n",
    "    '''Divides the signal into overlapping windows and applies FFT to each segment'''\n",
    "    features = []\n",
    "    for ch in x.T:\n",
    "        f, t, Zxx = signal.stft(ch, fs=fs, nperseg=nperseg, noverlap=noverlap)\n",
    "        power = np.abs(Zxx) ** 2\n",
    "        log_power = np.log1p(np.mean(power, axis=1))  # Mean over time\n",
    "        features.append(log_power)\n",
    "    return np.stack(features) \n",
    "\n",
    "def wavelet_energy(x, wavelet='db4', level=4):\n",
    "    '''Extracts features from multichannel EEG data using the Discrete Wavelet Transform'''\n",
    "    result = []\n",
    "    for ch in x.T:\n",
    "        coeffs = pywt.wavedec(ch, wavelet, level=level)\n",
    "        energies = [np.log1p(np.sum(np.square(c))) for c in coeffs]\n",
    "        result.append(energies)\n",
    "    return np.stack(result)\n",
    "\n",
    "def bandpower(x, fs=250):\n",
    "    '''Estimates the signal power within standard EEG frequency bands (e.g., delta, theta, alpha, beta)'''\n",
    "    bands = [(0.5, 4), (4, 8), (8, 12), (12, 30)]\n",
    "    result = []\n",
    "    for ch in x.T:\n",
    "        f, Pxx = welch(ch, fs=fs, nperseg=256)\n",
    "        bandpowers = [np.log1p(np.trapz(Pxx[(f >= low) & (f < high)], f[(f >= low) & (f < high)])) for low, high in bands]\n",
    "        result.append(bandpowers)\n",
    "    return np.stack(result)\n",
    "\n",
    "def combined_transform(x):\n",
    "    \"\"\"Concatenate wavelet + bandpower + STFT per channel\"\"\"\n",
    "    x = signal.sosfiltfilt(bp_filter, x, axis=0)  \n",
    "\n",
    "    wvlt = wavelet_energy(x)    \n",
    "    bp = bandpower(x)           \n",
    "    stft = stft_transform(x)    \n",
    "\n",
    "    assert wvlt.shape[0] == bp.shape[0] == stft.shape[0]\n",
    "\n",
    "    out = np.concatenate([wvlt, bp, stft], axis=1)  # along features\n",
    "    return out  \n",
    "\n",
    "def normalize_features(feat: np.ndarray, axis=0, eps=1e-8) -> np.ndarray:\n",
    "    \"\"\"Z-score normalization per channel or feature\"\"\"\n",
    "    mean = feat.mean(axis=axis, keepdims=True)\n",
    "    std = feat.std(axis=axis, keepdims=True) + eps\n",
    "    return (feat - mean) / std\n",
    "\n",
    "def normalized_combined_transform(x):\n",
    "    \"\"\"Concatenate wavelet + bandpower + STFT per channel\"\"\"\n",
    "    x = signal.sosfiltfilt(bp_filter, x, axis=0) \n",
    "\n",
    "    # Extract features\n",
    "    wvlt = wavelet_energy(x)       \n",
    "    bp   = bandpower(x)            \n",
    "    stft = stft_transform(x)       \n",
    "\n",
    "    # Normalize each separately\n",
    "    wvlt = normalize_features(wvlt, axis=1)  \n",
    "    bp   = normalize_features(bp, axis=1)\n",
    "    stft = normalize_features(stft, axis=1)\n",
    "\n",
    "    # Combine features along feature axis\n",
    "    out = np.concatenate([wvlt, bp, stft], axis=1)\n",
    "    return out\n",
    "\n",
    "\n",
    "chosen_transform = combined_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e91c70-e05f-468b-a159-09f322f6ea35",
   "metadata": {},
   "source": [
    "### Train Validation Split based on Patient ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf3be8c-c1e4-4e8f-9755-361703579e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clips_tr = pd.read_parquet(\"train/segments.parquet\")\n",
    "\n",
    "def extract_patient_id(path):\n",
    "    fname = path.split(\"/\")[-1].split(\".\")[0]\n",
    "    return fname.split(\"_\")[0]\n",
    "\n",
    "clips_tr[\"patient_id\"] = clips_tr[\"signals_path\"].apply(extract_patient_id)\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "train_idx, val_idx = next(\n",
    "    gss.split(clips_tr, clips_tr[\"label\"], clips_tr[\"patient_id\"])\n",
    ")\n",
    "\n",
    "train_clips = clips_tr.iloc[train_idx].reset_index(drop=True)\n",
    "val_clips   = clips_tr.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "print(\"Patients total:\", clips_tr[\"patient_id\"].nunique())\n",
    "print(\"Train patients:\", train_clips[\"patient_id\"].nunique())\n",
    "print(\"Val   patients:\", val_clips[\"patient_id\"].nunique())\n",
    "\n",
    "dataset_tr = EEGDataset(\n",
    "    train_clips,\n",
    "    signals_root= \"train\",\n",
    "    signal_transform=chosen_transform,\n",
    "    prefetch=True,  # If your compute does not allow it, you can use prefetch=False\n",
    ")\n",
    "\n",
    "dataset_val = EEGDataset(\n",
    "    val_clips,\n",
    "    signals_root= \"train\",\n",
    "    signal_transform=chosen_transform,\n",
    "    prefetch=True,  # If your compute does not allow it, you can use prefetch=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ca6884-8374-46de-ab95-3bd6b7209923",
   "metadata": {},
   "source": [
    "### Train Validation Split based on Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d51b9e2-9a9b-49a8-b394-8dfcb1e057dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the signal_transform, or remove it completely\n",
    "dataset_tr = EEGDataset(\n",
    "    clips_tr,\n",
    "    signals_root=\"train\",\n",
    "    signal_transform=chosen_transform,\n",
    "    prefetch=False,  # If your compute does not allow it, you can use `prefetch=False`\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7081cb5-a2c6-4c21-bb96-9f9c630d3d7b",
   "metadata": {},
   "source": [
    "### Graph Construction Methods\n",
    "a) Distance Based Graph, edge weights are computed by applying a thresholded Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56782bf3-1d0c-4ae5-bcf7-09241831647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "dist_df = pd.read_csv(\n",
    "    \"distances_3d.csv\"\n",
    ")\n",
    "\n",
    "electrodes = sorted(set(dist_df['from']) | set(dist_df['to']))\n",
    "node2idx = {node: i for i, node in enumerate(electrodes)}\n",
    "\n",
    "edges = []\n",
    "weights = []\n",
    "\n",
    "sigma = dist_df['distance'].std() \n",
    "kappa = 0.9\n",
    "\n",
    "for f, t, d in zip(dist_df['from'], dist_df['to'], dist_df['distance']):\n",
    "    if d < kappa and d != 0.0:\n",
    "        u, v = node2idx[f], node2idx[t]\n",
    "        weight = np.exp(-np.square(d) / (sigma ** 2))\n",
    "        \n",
    "        edges.append([u, v])\n",
    "        edges.append([v, u])\n",
    "        weights.append(weight)\n",
    "        weights.append(weight)\n",
    "\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "edge_attr = torch.tensor(weights, dtype=torch.float)\n",
    "edge_index, edge_attr = to_undirected(edge_index, edge_attr)\n",
    "edge_index, edge_attr = add_self_loops(edge_index, edge_attr=edge_attr,\n",
    "                                       fill_value=1.0)\n",
    "\n",
    "print(f\"Edge index shape: {edge_index.shape}\")      \n",
    "print(\"First 5 edges:\\n\", edge_index[:, :5])\n",
    "print(\"First 5 edge weights:\\n\", edge_attr[:5])\n",
    "\n",
    "for x_np, y_np in tqdm(dataset_tr, desc=\"Converting dataset\"):\n",
    "    print(\"Original x_np shape:\", x_np.shape)  # likely [354, 19]\n",
    "    x = torch.tensor(x_np.T, dtype=torch.float)  # we expect [19, 354]\n",
    "    print(\"Transposed x shape:\", x.shape)\n",
    "    print(\"y shape:\", torch.tensor([y_np], dtype=torch.float).shape)\n",
    "    ...\n",
    "    break  \n",
    "\n",
    "new_dataset = []\n",
    "for x_np, y_np in tqdm(dataset_tr, desc=\"Converting dataset\"):\n",
    "    x = torch.tensor(x_np.T, dtype=torch.float)  \n",
    "    y = torch.tensor([y_np], dtype=torch.float)\n",
    "    graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr.unsqueeze(-1), y=y)\n",
    "    new_dataset.append(graph)\n",
    "\n",
    "dataset_tr_dist = new_dataset\n",
    "\n",
    "new_dataset = []\n",
    "for x_np, y_np in tqdm(dataset_val, desc=\"Converting dataset\"):\n",
    "    x = torch.tensor(x_np.T, dtype=torch.float)  \n",
    "    y = torch.tensor([y_np], dtype=torch.float)\n",
    "    graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr.unsqueeze(-1), y=y)\n",
    "    new_dataset.append(graph)\n",
    "\n",
    "dataset_val_dist = new_dataset\n",
    "\n",
    "loader_tr = DataLoader(dataset_tr_dist, batch_size=2**8, shuffle=True)\n",
    "loader_val = DataLoader(dataset_val_dist, batch_size=2**8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3aa54a-12f1-4e26-9a75-bf5275e893ad",
   "metadata": {},
   "source": [
    "### Graph Construction Methods\n",
    "b) Distance Based Graph, edge weights are computed by 1/d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3be312-07ce-4861-827b-5f89cf416976",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df = pd.read_csv(\n",
    "    \"distances_3d.csv\"\n",
    ")\n",
    "\n",
    "electrodes = sorted(set(dist_df['from']) | set(dist_df['to']))\n",
    "node2idx = {node: i for i, node in enumerate(electrodes)}\n",
    "\n",
    "# Step 3: Build edge_index and edge_attr\n",
    "edges = []\n",
    "weights = []\n",
    "\n",
    "for f, t, d in zip(dist_df['from'], dist_df['to'], dist_df['distance']):\n",
    "    if d > 0:\n",
    "        u, v = node2idx[f], node2idx[t]\n",
    "        weight = 1.0 / d\n",
    "        # Add both directions for undirected graph\n",
    "        edges.append([u, v])\n",
    "        edges.append([v, u])\n",
    "        weights.append(weight)\n",
    "        weights.append(weight)\n",
    "\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "edge_attr = torch.tensor(weights, dtype=torch.float)\n",
    "\n",
    "print(f\"Edge index shape: {edge_index.shape}\")       # Should be [2, num_edges * 2]\n",
    "print(\"First 5 edges:\\n\", edge_index[:, :5])\n",
    "print(\"First 5 edge weights:\\n\", edge_attr[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c78da5-354a-4f24-bc19-e1accd8c65a1",
   "metadata": {},
   "source": [
    "### Graph Construction Methods\n",
    "c) Distance Based Graph, based on k-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f34439-3bb4-4586-8aab-831ab7fb7b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df = pd.read_csv(\n",
    "    \"distances_3d.csv\"\n",
    ")\n",
    "\n",
    "electrodes = sorted(set(dist_df['from']) | set(dist_df['to']))\n",
    "node2idx = {node: i for i, node in enumerate(electrodes)}\n",
    "\n",
    "k = 5\n",
    "edges_knn = []\n",
    "\n",
    "for node in dist_df['from'].unique():\n",
    "    sub = dist_df[dist_df['from'] == node].sort_values(by='distance').head(k)\n",
    "    for _, row in sub.iterrows():\n",
    "        u, v = node2idx[row['from']], node2idx[row['to']]\n",
    "        edges_knn.append([u, v])\n",
    "        edges_knn.append([v, u])  # undirected\n",
    "\n",
    "edge_index_knn = torch.tensor(edges, dtype=torch.long).t().contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cbd7f8-d65b-4816-9b82-6d3b2b7b03e5",
   "metadata": {},
   "source": [
    "### Graph Construction Methods\n",
    "d) Distance Based Graph, based on mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0368c-7cbc-493d-a3ed-c86881380988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mi_matrix(X, bins=16):\n",
    "    \"\"\"\n",
    "    Compute pairwise mutual information between EEG channels.\n",
    "    X: shape [channels, time]\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    mi_matrix = np.zeros((n, n))\n",
    "\n",
    "    # Discretize signals per channel\n",
    "    X_disc = np.floor((X - X.min(axis=1, keepdims=True)) /\n",
    "                      (X.max(axis=1, keepdims=True) - X.min(axis=1, keepdims=True) + 1e-8) * (bins - 1)).astype(int)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            mi = mutual_info_score(X_disc[i], X_disc[j])\n",
    "            mi_matrix[i, j] = mi\n",
    "            mi_matrix[j, i] = mi  # symmetric\n",
    "\n",
    "    # Normalize the MI matrix\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            mi_matrix[i, j] /= min(mi_matrix[i, i], mi_matrix[j, j]) + 1e-8\n",
    "\n",
    "    return mi_matrix\n",
    "\n",
    "def average_mi_over_dataset(dataset, n_segments=100):\n",
    "    x0, _ = dataset[0]\n",
    "    n_channels = x0.shape[0]\n",
    "    mi_sum = np.zeros((n_channels, n_channels))\n",
    "\n",
    "    for i in range(min(n_segments, len(dataset))):\n",
    "        x_np, _ = dataset[i]\n",
    "        mi_sum += compute_mi_matrix(x_np)\n",
    "\n",
    "    return mi_sum / n_segments\n",
    "\n",
    "\n",
    "def mi_to_graph(mi_matrix, k=4):\n",
    "    edge_list = []\n",
    "    edge_weights = []\n",
    "\n",
    "    for i in range(mi_matrix.shape[0]):\n",
    "        top_k = np.argsort(mi_matrix[i])[-k:]\n",
    "        for j in top_k:\n",
    "            if i != j:\n",
    "                edge_list.append([i, j])\n",
    "                edge_list.append([j, i])\n",
    "                edge_weights.append(mi_matrix[i, j])\n",
    "                edge_weights.append(mi_matrix[i, j])  # symmetric\n",
    "\n",
    "    edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_weights, dtype=torch.float)\n",
    "    return edge_index, edge_attr\n",
    "\n",
    "# Compute MI matrix\n",
    "mi_matrix = average_mi_over_dataset(dataset_tr, n_segments=100)\n",
    "\n",
    "# Build graph with top-8 MI neighbors per node\n",
    "edge_index, edge_attr = mi_to_graph(mi_matrix, k=19)\n",
    "\n",
    "# Final check\n",
    "print(\"Edge index shape:\", edge_index.shape)\n",
    "print(\"Edge attr shape:\", edge_attr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1958636-91fe-435d-960d-09a5618fae19",
   "metadata": {},
   "source": [
    "### Graph Construction Methods\n",
    "e) Correlation Based Graph\n",
    "Based on the work in [here](https://github.com/tsy935/eeg-gnn-ssl), constructing graph by calculating the normalized cross-correlation between the EEG channels, instead of constructing inplace, since we have less data, we constructed the graph at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38993378-e808-4a50-811e-9201a8fc2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_xcorr(x, y, mode=\"valid\", normalize=True):\n",
    "    \"\"\"\n",
    "    Compute cross-correlation between 2 1D signals x, y\n",
    "    Args:\n",
    "        x: 1D array\n",
    "        y: 1D array\n",
    "        mode: 'valid', 'full' or 'same',\n",
    "            refer to https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.correlate.html\n",
    "        normalize: If True, will normalize cross-correlation\n",
    "    Returns:\n",
    "        xcorr: cross-correlation of x and y\n",
    "    \"\"\"\n",
    "    xcorr = correlate(x, y, mode=mode)\n",
    "    # the below normalization code refers to matlab xcorr function\n",
    "    cxx0 = np.sum(np.absolute(x) ** 2)\n",
    "    cyy0 = np.sum(np.absolute(y) ** 2)\n",
    "    if normalize and (cxx0 != 0) and (cyy0 != 0):\n",
    "        scale = (cxx0 * cyy0) ** 0.5\n",
    "        xcorr /= scale\n",
    "    return xcorr\n",
    "    \n",
    "def keep_topk(adj_mat, top_k=3, directed=True):\n",
    "    \"\"\" \"\n",
    "    Helper function to sparsen the adjacency matrix by keeping top-k neighbors\n",
    "    for each node.\n",
    "    Args:\n",
    "        adj_mat: adjacency matrix, shape (num_nodes, num_nodes)\n",
    "        top_k: int\n",
    "        directed: whether or not a directed graph\n",
    "    Returns:\n",
    "        adj_mat: sparse adjacency matrix, directed graph\n",
    "    \"\"\"\n",
    "    # Set values that are not of top-k neighbors to 0:\n",
    "    adj_mat_noSelfEdge = adj_mat.copy()\n",
    "    for i in range(adj_mat_noSelfEdge.shape[0]):\n",
    "        adj_mat_noSelfEdge[i, i] = 0\n",
    "\n",
    "    top_k_idx = (-adj_mat_noSelfEdge).argsort(axis=-1)[:, :top_k]\n",
    "\n",
    "    mask = np.eye(adj_mat.shape[0], dtype=bool)\n",
    "    for i in range(0, top_k_idx.shape[0]):\n",
    "        for j in range(0, top_k_idx.shape[1]):\n",
    "            mask[i, top_k_idx[i, j]] = 1\n",
    "            if not directed:\n",
    "                mask[top_k_idx[i, j], i] = 1  # symmetric\n",
    "\n",
    "    adj_mat = mask * adj_mat\n",
    "    return adj_mat\n",
    "\n",
    "def ccor_edge_attr(dataset_tr, with_label):\n",
    "\n",
    "    num_sensors = 19\n",
    "    new_dataset = []\n",
    "    labels = []\n",
    "\n",
    "    for x in dataset_tr:\n",
    "\n",
    "        if with_label:\n",
    "            clip, label = x\n",
    "            clip = clip.T\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            clip, idx = x\n",
    "            clip = clip.T\n",
    "            labels.append(idx)\n",
    "            \n",
    "        if clip.ndim == 2:\n",
    "            clip = clip[:, :, None]\n",
    "        adj_mat = np.eye(num_sensors, num_sensors, dtype=np.float32)\n",
    "        \n",
    "        clip = np.transpose(clip, (1, 0, 2))\n",
    "        \n",
    "        clip = clip.reshape((num_sensors, -1))\n",
    "        # print(clip.shape)\n",
    "        for i in range(0, num_sensors):\n",
    "            for j in range(i + 1, num_sensors):\n",
    "                xcorr = comp_xcorr(\n",
    "                    clip[i, :], clip[j, :], mode='valid', normalize=True)\n",
    "                adj_mat[i, j] = xcorr\n",
    "                adj_mat[j, i] = xcorr\n",
    "        adj_mat = abs(adj_mat)\n",
    "        W = keep_topk(adj_mat, top_k=3, directed=True)\n",
    "        src, dst, w = [], [], []\n",
    "        for i in range(W.shape[0]):\n",
    "            for j in range(W.shape[1]):\n",
    "                if W[i, j] != 0:\n",
    "                    src.append(i); dst.append(j); w.append(W[i, j])\n",
    "    \n",
    "        edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "        edge_attr  = torch.tensor(w, dtype=torch.float).unsqueeze(-1)\n",
    "        data = torch.tensor(clip, dtype=torch.float)\n",
    "        if with_label:\n",
    "            y = torch.tensor([label], dtype=torch.float)\n",
    "            graph = Data(x=data, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "        else:\n",
    "            graph = Data(x=data, edge_index=edge_index, edge_attr=edge_attr, idx=idx)\n",
    "        new_dataset.append(graph)\n",
    "    \n",
    "    return new_dataset, labels\n",
    "\n",
    "dataset_tr_ccor, labels = ccor_edge_attr(dataset_tr, True) \n",
    "dataset_val_ccor, labels = ccor_edge_attr(dataset_val, True) \n",
    "\n",
    "loader_tr = DataLoader(dataset_tr_ccor, batch_size=2**8, shuffle=True)\n",
    "loader_val = DataLoader(dataset_val_ccor, batch_size=2**8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c2798",
   "metadata": {},
   "source": [
    "### Graph Construction Methods\n",
    "f) Undirected graph based on 10-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a3bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = [\n",
    "    (0, 10), (0, 2), (0, 16), (0, 1),       # FP1 → F7, F3, FZ, FP2\n",
    "    (1, 0), (1, 16), (1, 3), (1, 11),       # FP2 → FP1, FZ, F4, F8\n",
    "    (2, 0), (2, 10), (2, 4), (2, 16),       # F3 → FP1, F7, C3, FZ\n",
    "    (3, 1), (3, 16), (3, 5), (3, 11),       # F4 → FP2, FZ, C4, F8\n",
    "    (4, 2), (4, 12), (4, 6), (4, 17),       # C3 → F3, T3, P3, CZ\n",
    "    (5, 3), (5, 17), (5, 7), (5, 13),       # C4 → F4, CZ, P4, T4\n",
    "    (6, 4), (6, 14), (6, 8), (6, 18),       # P3 → C3, T5, O1, PZ\n",
    "    (7, 5), (7, 18), (7, 9), (7, 15),       # P4 → C4, PZ, O2, T6\n",
    "    (8, 14), (8, 6), (8, 18), (8, 9),       # O1 → T5, P3, PZ, O2\n",
    "    (9, 8), (9, 18), (9, 7), (9, 15),       # O2 → O1, PZ, P4, T6\n",
    "    (10, 0), (10, 2), (10, 12),             # F7 → FP1, F3, T3\n",
    "    (11, 1), (11, 3), (11, 13),             # F8 → FP2, F4, T4\n",
    "    (12, 10), (12, 4), (12, 14),            # T3 → F7, C3, T5\n",
    "    (13, 11), (13, 5), (13, 15),            # T4 → F8, C4, T6\n",
    "    (14, 12), (14, 6), (14, 8),             # T5 → T3, P3, O1\n",
    "    (15, 13), (15, 7), (15, 9),             # T6 → T4, P4, O2\n",
    "    (16, 0), (16, 1), (16, 2), (16, 3), (16, 17),  # FZ → FP1, FP2, F3, F4, CZ\n",
    "    (17, 4), (17, 5), (17, 16), (17, 18),   # CZ → C3, C4, FZ, PZ\n",
    "    (18, 6), (18, 7), (18, 8), (18, 9), (18, 17)  # PZ → P3, P4, O1, O2, CZ\n",
    "]\n",
    "\n",
    "class EEGGraphDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, eeg_dataset, edge_index, use_supernode=False, return_id=False):\n",
    "        self.eeg_dataset = eeg_dataset\n",
    "        self.edge_index = edge_index\n",
    "        self.use_supernode = use_supernode\n",
    "        self.return_id = return_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eeg_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.return_id:\n",
    "            x_np, sample_id = self.eeg_dataset[idx]\n",
    "        else:\n",
    "            x_np, y = self.eeg_dataset[idx]\n",
    "\n",
    "        x = torch.tensor(x_np, dtype=torch.float)\n",
    "\n",
    "        if self.use_supernode:\n",
    "            x_super = x.mean(dim=0, keepdim=True)\n",
    "            x = torch.cat([x, x_super], dim=0)\n",
    "            supernode_edges = [(i, 19) for i in range(19)]\n",
    "            full_edges = self.edge_index + supernode_edges\n",
    "            edge_index = torch.tensor(full_edges, dtype=torch.long).T\n",
    "        else:\n",
    "            edge_index = torch.tensor(self.edge_index, dtype=torch.long).T\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "        if self.return_id:\n",
    "            return data, sample_id\n",
    "        else:\n",
    "            y = torch.tensor([y], dtype=torch.long)\n",
    "            data.y = y\n",
    "            return data\n",
    "\n",
    "\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).T\n",
    "graph_dataset = EEGGraphDataset(dataset_tr, edges, use_supernode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650d637-1dfe-4760-aaa1-e548260934c4",
   "metadata": {},
   "source": [
    "# Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60cd9ca-67e3-4c1d-8b32-edb54aa9e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_data(x_batch, y_batch, edge_index, edge_attr):\n",
    "    graphs = []\n",
    "\n",
    "    for x, y in zip(x_batch, y_batch):\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float)        # [num_nodes, num_features]\n",
    "        y_tensor = torch.tensor([y], dtype=torch.float)       # [1] or [1,1] for BCE/MSE\n",
    "        graph = Data(x=x_tensor, edge_index=edge_index, edge_attr=edge_attr, y=y_tensor)\n",
    "        graphs.append(graph)\n",
    "\n",
    "    return graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e560039b-fa5c-4989-a43a-1b6702560225",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "a) GIN\n",
    "- Architecture with two GIN layers followed by concatenating add, mean and max pooling and a classification head.\n",
    "- To include edge features into learning GINEConv is used instead of GINConv.\n",
    "- Added random dropout of edges in training mode to help model generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46cac84-1186-4ad1-9c0e-13b9d44382a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIN_with_edge(torch.nn.Module):\n",
    "    def __init__(self, input_dim=19, hidden_dim=64, dropout=0.2, edge_dim = 1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = GINEConv(\n",
    "            Sequential(\n",
    "                Linear(input_dim,  hidden_dim),\n",
    "                BatchNorm1d(hidden_dim), ReLU(),\n",
    "                #Dropout(0.2),\n",
    "                Linear(hidden_dim, hidden_dim), ReLU()\n",
    "            ),\n",
    "            edge_dim=edge_dim,\n",
    "        )\n",
    "        \n",
    "        self.conv2 = GINEConv(\n",
    "            Sequential(\n",
    "                Linear(hidden_dim, hidden_dim),\n",
    "                BatchNorm1d(hidden_dim), ReLU(),\n",
    "                # Dropout(0.2),\n",
    "                Linear(hidden_dim, hidden_dim), ReLU()\n",
    "            ),\n",
    "            edge_dim=edge_dim,\n",
    "        )\n",
    "\n",
    "        self.lin1 = Linear(hidden_dim*3, hidden_dim)\n",
    "        self.lin2 = Linear(hidden_dim, 1)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "\n",
    "        # Randomly drop edges\n",
    "        if self.training:       \n",
    "            E = edge_index.size(1)\n",
    "            p = 0.2\n",
    "            mask = torch.rand(E, device=edge_index.device) >= p\n",
    "            edge_index = edge_index[:, mask]\n",
    "            edge_attr = edge_attr[mask]\n",
    "            \n",
    "        h1 = self.conv1(x, edge_index, edge_attr)\n",
    "        h2 = self.conv2(h1, edge_index, edge_attr)\n",
    "\n",
    "        h_sum  = global_add_pool(h2, batch)\n",
    "        h_mean = global_mean_pool(h2, batch)\n",
    "        h_max  = global_max_pool(h2, batch)\n",
    "        h = torch.cat([h_sum, h_mean, h_max], dim=1)\n",
    "        \n",
    "        h = self.lin1(h).relu()\n",
    "        h = F.dropout(h, p=0.2, training=self.training)\n",
    "        h = self.lin2(h).squeeze(1)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d369cfd8-deb5-4514-a1cb-d4c927f5b6fe",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "b) GCN Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43943a8f-095c-4233-b8a3-9eef5f101da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.classifier = nn.Linear(out_channels, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, batch):\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_weight=edge_weight)\n",
    "        x = global_mean_pool(x, batch)  # Graph-level representation\n",
    "        x = self.classifier(x)\n",
    "        return x  # [batch_size, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da310330-8f32-428e-9c83-ad3057e47776",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "c) GCN v2 Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88139fa7-6be7-4458-82a2-d073d80f4ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_GCN_v2(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.bn1 = BatchNorm(hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.bn2 = BatchNorm(out_channels)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(out_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, batch):\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index, edge_weight=edge_weight)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4764442a-68b9-410f-9555-2b7f68302404",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "d) Graph SAGE SAmple and aggreGatE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6284191b-f505-46c0-9cb5-05363f992aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_SAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "        self.classifier = nn.Linear(out_channels, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)  # Graph-level representation\n",
    "        x = self.classifier(x)\n",
    "        return x  # [batch_size, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd9e2c7-fe78-49ff-835c-063464c55807",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "e) Graph SAGE v2 SAmple and aggreGatE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a336bba4-b1b1-4b53-88ab-3d55ca0d0c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_SAGE_v2(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.bn1 = BatchNorm(hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "        self.bn2 = BatchNorm(out_channels)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(out_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9664e6c8-4e1d-42c1-a7cf-f4f5cc81499d",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "f) STGNN Spatiotemporal Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc5470-570c-4e66-876c-ccc1796795b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STGNN_EEG(nn.Module):\n",
    "    def __init__(self, time_steps, temporal_out=32, gcn_hidden=64):\n",
    "        super().__init__()\n",
    "\n",
    "        # Temporal encoder: Conv1D over [T] dimension of each node\n",
    "        self.temporal = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=7, stride=2, padding=3),  # [B*19, 1, T] → [B*19, 16, T']\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(16, temporal_out, kernel_size=5, stride=2, padding=2),  # [B*19, 32, T'']\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.gcn1 = GCNConv(temporal_out, gcn_hidden)\n",
    "        self.gcn2 = GCNConv(gcn_hidden, gcn_hidden)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2 * gcn_hidden, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 1)  # Binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        # Input x shape: [B*19, T] → reshape to [B*19, 1, T]\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.temporal(x)  # [B*19, C, T']\n",
    "        x = x.mean(dim=2)     # Temporal average → [B*19, temporal_out]\n",
    "\n",
    "        x = self.gcn1(x, edge_index, edge_weight=edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.gcn2(x, edge_index, edge_weight=edge_weight)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Spatio-temporal pooling\n",
    "        x_mean = global_mean_pool(x, batch)\n",
    "        x_max = global_max_pool(x, batch)\n",
    "        x = torch.cat([x_mean, x_max], dim=1)\n",
    "\n",
    "        return self.classifier(x)  # [B, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71189144-57ff-46b9-933e-63cc2cc44282",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "g) ChebNet Chebyshev Graph Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d1fca-a350-42dc-9e33-68236b85a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_ChebNet(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, K=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = ChebConv(in_channels, hidden_channels, K=K)\n",
    "        self.conv2 = ChebConv(hidden_channels, hidden_channels, K=K)\n",
    "        self.classifier = nn.Linear(hidden_channels, out_channels)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, batch):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c72d402-c1d8-48b9-9ec7-98dffba2bcf2",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "h) ChebNet Attention Extended version with a global attention mechanism for pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faaf53b-b96f-46d0-9d17-24c86a2d5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_ChebNet_Attn(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, K=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = ChebConv(in_channels, hidden_channels, K=K)\n",
    "        self.conv2 = ChebConv(hidden_channels, hidden_channels, K=K)\n",
    "\n",
    "        # Global attention pooling with learnable gate\n",
    "        self.attn_pool = GlobalAttention(gate_nn=nn.Sequential(\n",
    "            nn.Linear(hidden_channels, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        ))\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_channels, out_channels)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, batch):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.attn_pool(x, batch)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37aec7d-7cd1-4391-9910-843cb9b013a4",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "i) ChebNet Residual Extended version having residual connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3af713-36f7-4167-b484-715fdc470898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_ChebNet_Res(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, K=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = ChebConv(in_channels, hidden_channels, K=K)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = ChebConv(hidden_channels, hidden_channels, K=K)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_channels)\n",
    "        self.classifier = nn.Linear(hidden_channels, out_channels)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Project input to match hidden_channels for residual path (if needed)\n",
    "        self.res_proj = nn.Linear(in_channels, hidden_channels) if in_channels != hidden_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, batch):\n",
    "        res = self.res_proj(x)  # Project for residual\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x + res)  # Residual connection\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        res2 = x  # second residual\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x + res2)  # Second residual\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6d7aea-d92b-48a6-9447-2a16d70b97fe",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "j) ChebNet Res Attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73502381-c7d8-4b56-a30d-d91e8c56ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_ChebNet_ResAttn(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, K=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = ChebConv(in_channels, hidden_channels, K=K)\n",
    "        self.bn1 = BatchNorm(hidden_channels)\n",
    "        self.res1 = nn.Linear(in_channels, hidden_channels) if in_channels != hidden_channels else nn.Identity()\n",
    "\n",
    "        self.conv2 = ChebConv(hidden_channels, hidden_channels, K=K)\n",
    "        self.bn2 = BatchNorm(hidden_channels)\n",
    "\n",
    "        self.attn_pool = GlobalAttention(gate_nn=nn.Sequential(\n",
    "            nn.Linear(hidden_channels, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        ))\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, batch):\n",
    "        # First residual block\n",
    "        res1 = self.res1(x)\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x + res1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Second residual block\n",
    "        res2 = x\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x + res2)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Attention-based global pooling\n",
    "        x = self.attn_pool(x, batch)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7411c140",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "k) GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b1bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGGAT(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim=1, heads=(4, 4), dropout=0.2, use_concat=True):\n",
    "        super().__init__()\n",
    "        self.use_concat = use_concat\n",
    "\n",
    "        self.gat1 = GATConv(in_dim, hidden_dim, heads=heads[0], concat=use_concat, dropout=dropout)\n",
    "        gat1_out_dim = hidden_dim * heads[0] \n",
    "\n",
    "        self.gat2 = GATConv(gat1_out_dim, hidden_dim, heads=heads[1], concat=use_concat, dropout=dropout)\n",
    "        gat2_out_dim = hidden_dim * heads[1] \n",
    "\n",
    "        self.head = torch.nn.Linear(gat2_out_dim, hidden_dim)\n",
    "        self.classifier = torch.nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        x = F.relu(self.head(x))\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "\n",
    "        out = self.classifier(x)      # Graph-level output\n",
    "        return out.squeeze(1)           # Shape: (batch_size,)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a284e",
   "metadata": {},
   "source": [
    "### MODELS\n",
    "l) GAT with supernode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f705c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGGAT_superpool(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim=1, heads=(4, 4), dropout=0.2, use_concat=True):\n",
    "        super().__init__()\n",
    "        self.use_concat = use_concat\n",
    "\n",
    "        self.gat1 = GATConv(in_dim, hidden_dim, heads=heads[0], concat=use_concat, dropout=dropout)\n",
    "        gat1_out_dim = hidden_dim * heads[0] \n",
    "\n",
    "        self.gat2 = GATConv(gat1_out_dim, hidden_dim, heads=heads[1], concat=use_concat, dropout=dropout)\n",
    "        gat2_out_dim = hidden_dim * heads[1] \n",
    "\n",
    "        self.head = torch.nn.Linear(gat2_out_dim, hidden_dim)\n",
    "        self.classifier = torch.nn.Linear(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = self.gat2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        # Get supernode from each graph (assumed at index 19)\n",
    "        num_graphs = batch.max().item() + 1\n",
    "        supernode_indices = (torch.arange(num_graphs, device=x.device) * 20) + 19\n",
    "        x_super = x[supernode_indices]\n",
    "\n",
    "        x_super = F.relu(self.head(x_super))\n",
    "        x_super = F.dropout(x_super, p=0.3, training=self.training)\n",
    "\n",
    "        out = self.classifier(x_super)\n",
    "        \n",
    "        return out.squeeze(1)           # Shape: (batch_size,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
